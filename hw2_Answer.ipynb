{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed9e8fef",
   "metadata": {},
   "source": [
    "Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "7e406623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              g        x1        x2\n",
      "Date                               \n",
      "2005-01-06  1.0  0.003506 -0.003074\n",
      "2005-01-07 -1.0 -0.001431  0.008811\n",
      "2005-01-13 -1.0 -0.008630 -0.011280\n",
      "2005-01-14  1.0  0.006005  0.002832\n",
      "2005-01-20 -1.0 -0.007783  0.001562\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# 加载数据文件，并对日期进行预处理\n",
    "# Load the data file and preprocess the dates.\n",
    "nikkei_data = pd.read_csv('./hw2 data/nikkei_daily.txt', sep='\\t', parse_dates=['Date'])\n",
    "sp_data = pd.read_csv('./hw2 data/sp_daily.txt', sep=r'\\s+')\n",
    "ex_data = pd.read_csv('./hw2 data/ex_daily.txt', sep=r'\\s+')\n",
    "\n",
    "nikkei_data.set_index('Date', inplace=True)\n",
    "sp_data['caldt'] = pd.to_datetime(sp_data['caldt'].astype(str), format='%Y%m%d')\n",
    "sp_data.set_index('caldt', inplace=True)\n",
    "sp_data.index.name = 'Date'\n",
    "ex_data['DATE'] = pd.to_datetime(ex_data['DATE'])\n",
    "ex_data.set_index('DATE', inplace=True)\n",
    "ex_data.index.name = 'Date'\n",
    "\n",
    "# 根据题目所给区间过滤指定日期范围的数据\n",
    "# Filter the data within the specified date range according to the interval given in the question\n",
    "start_date = '2005-01-03'\n",
    "end_date = '2007-12-31'\n",
    "\n",
    "# 获取指定日期范围内所有三个数据集都有的日期\n",
    "# Obtain the dates that exist in all three datasets within the specified date range.\n",
    "nikkei_dates = set(nikkei_data.loc[start_date:end_date].index)\n",
    "sp_dates = set(sp_data.loc[start_date:end_date].index)\n",
    "ex_dates = set(ex_data.loc[start_date:end_date].index)\n",
    "common_dates = sorted(nikkei_dates & sp_dates & ex_dates)\n",
    "\n",
    "# 创建一个包含共同日期的数据框\n",
    "# Create a dataframe containing the common dates\n",
    "result = pd.DataFrame(index=common_dates)\n",
    "result.index.name = 'Date'\n",
    "\n",
    "# 对每个日期，检查其是否有可用的(i-1)天数据和(i-2)天数据，以筛选出可用数据点\n",
    "# For each date, check if there is available data for the (i - 1)th day and the (i - 2)th day to filter out the available data points.\n",
    "for i in range(len(common_dates)):\n",
    "    current_date = common_dates[i]\n",
    "\n",
    "    prev_date = common_dates[i-1]\n",
    "    prev_prev_date = common_dates[i-2]\n",
    "    \n",
    "    days_since_prev = (current_date - prev_date).days\n",
    "    days_between_prev = (prev_date - prev_prev_date).days\n",
    "\n",
    "    if days_since_prev == 1 and days_between_prev == 1:\n",
    "\n",
    "        # g\n",
    "        nikkei_current = nikkei_data.loc[current_date, 'Value']\n",
    "        nikkei_prev = nikkei_data.loc[prev_date, 'Value']\n",
    "        result.loc[current_date, 'g'] = 1 if nikkei_current > nikkei_prev else -1\n",
    "        \n",
    "        # x1\n",
    "        result.loc[current_date, 'x1'] = sp_data.loc[current_date, 'sprtrn']\n",
    "        \n",
    "        # x2\n",
    "        ex_prev = ex_data.loc[prev_date, 'VALUE']\n",
    "        ex_prev_prev = ex_data.loc[prev_prev_date, 'VALUE']\n",
    "        result.loc[current_date, 'x2'] = np.log(ex_prev) - np.log(ex_prev_prev)\n",
    "\n",
    "result = result.dropna()\n",
    "\n",
    "# 打印经过筛查后得到的可用数据的前几项，经过人工检验确认无误\n",
    "# Print the first few items of the available data obtained after screening. Manual inspection confirms that they are correct.\n",
    "print(result.head())\n",
    "\n",
    "# 提取特征和标签\n",
    "# Extract features and labels\n",
    "X = result[['x1', 'x2']].values\n",
    "label = result['g'].values\n",
    "\n",
    "# 按题设划分后60天作为测试集，其余样本为训练集，以预备性能评估。\n",
    "# Divide the data according to the problem statement, with the last 60 days as the test set and the remaining samples as the training set, in preparation for performance evaluation.\n",
    "# 同时，为了优化分类器性能，这里使用多项式特征工程添加了特征：x1^2, x2^2, x1*x2. 故输入的特征向量维数为5。\n",
    "# Meanwhile, to optimize the performance of the classifier, polynomial feature engineering is used here to add features: x1^2, x2^2, x1*x2. Therefore, the dimension of the input feature vector is 5.\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train_poly = X_poly[:-60]\n",
    "X_test_poly = X_poly[-60:]\n",
    "\n",
    "# 最后，对需要使用的输入特征进行标准化。\n",
    "# Finally, standardize the input features that need to be used.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_poly) \n",
    "X_test = scaler.transform(X_test_poly)\n",
    "\n",
    "# X_train = scaler.fit_transform(X[:-60]) \n",
    "# X_test = scaler.transform(X[-60:])\n",
    "\n",
    "label_train = label[:-60]\n",
    "label_test = label[-60:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806bffcd",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "ef9906a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate of logistic regression on the training set is: 0.4307\n",
      "The error rate of logistic regression on the test set is: 0.4333\n"
     ]
    }
   ],
   "source": [
    "# (i).Logistic regression\n",
    "\n",
    "logistic = LogisticRegression(random_state=0)\n",
    "logistic.fit(X_train, label_train)\n",
    "\n",
    "# 计算训练误差率\n",
    "# Calculate the training error rate\n",
    "logistic_hat1 = logistic.predict(X_train)\n",
    "logistic_ac1 = accuracy_score(label_train, logistic_hat1)\n",
    "logistic_er1 = 1 - logistic_ac1\n",
    "\n",
    "# 计算测试误差率\n",
    "# Calculate the test error rate\n",
    "logistic_hat2 = logistic.predict(X_test)\n",
    "logistic_ac2 = accuracy_score(label_test, logistic_hat2)\n",
    "logistic_er2 = 1 - logistic_ac2\n",
    "\n",
    "print('The error rate of logistic regression on the training set is:', f'{logistic_er1:.4f}')\n",
    "print('The error rate of logistic regression on the test set is:', f'{logistic_er2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "d45be769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(X, y, n=10, test_size=None, gap=0):\n",
    "    \"\"\"\n",
    "    CV的准备函数，用于根据折数分割训练集和验证集\n",
    "    The preparation function for CV, which is used to split the training set and validation set according to the number of folds\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    if test_size is None:\n",
    "        test_size = n_samples // (n + 1)    \n",
    "    \n",
    "    # 处理余数。由于特征的时间序列特性，同时确保验证集索引不在训练集之前\n",
    "    # Handle the remainder. Due to the time - series characteristics of the features, also ensure that the validation set indices are not before those of the training set.\n",
    "    folds = []\n",
    "    train_size = n_samples - n * test_size\n",
    "    for i in range(n):\n",
    "        train_end = train_size + i * test_size\n",
    "        test_start = train_end + gap\n",
    "        test_end = test_start + test_size\n",
    "        if test_end > n_samples:\n",
    "            test_end = n_samples\n",
    "            if test_start >= test_end:\n",
    "                break\n",
    "        \n",
    "        train_indices = np.arange(train_end)\n",
    "        test_indices = np.arange(test_start, test_end)\n",
    "        folds.append((train_indices, test_indices))\n",
    "    return folds\n",
    "\n",
    "\n",
    "def cross_validation_1(X, y, C_range, n=10):\n",
    "    \"\"\"\n",
    "    线性核SVM的交叉验证函数，默认10折，寻找最优的参数C\n",
    "    The cross-validation function for linear-kernel SVM, with the default of 10-fold, to find the optimal parameter C\n",
    "    \"\"\"\n",
    "    folds = kfold(X, y, n=n)\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    \n",
    "    # 对每个c进行循环\n",
    "    # Loop through each c\n",
    "    for c in C_range:\n",
    "        scores = []\n",
    "        \n",
    "        # 对每一折进行训练和验证\n",
    "        # Train and validate for each fold\n",
    "        for train_idx, val_idx in folds:\n",
    "            X_train_fold, y_train_fold = X[train_idx], y[train_idx]\n",
    "            X_val_fold, y_val_fold = X[val_idx], y[val_idx]\n",
    "            \n",
    "            # 使用当前参数创建并训练模型\n",
    "            # Create and train the model with the current parameters\n",
    "            model = SVC(C=c, kernel='linear', random_state=0)\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            \n",
    "            # 在验证集上计算准确率\n",
    "            # Calculate the accuracy on the validation set\n",
    "            y_pred = model.predict(X_val_fold)\n",
    "            accuracy = np.mean(y_pred == y_val_fold)\n",
    "            scores.append(accuracy)\n",
    "        \n",
    "        # 计算平均准确率，并更新最佳参数\n",
    "        # Calculate the average accuracy, and update the best parameters\n",
    "        mean_score = np.mean(scores)\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = c\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "eff13092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate of the linear-kernel SVM on the training set is: 0.4428\n",
      "The error rate of the linear-kernel SVM on the test set is: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# (ii).SVM with linear kernel\n",
    "\n",
    "# 设定参数C的范围并进行10折交叉验证找到最优的C\n",
    "# Set the range of parameter C and perform 10-fold cross-validation to find the optimal C.\n",
    "C_range = [0.1, 1, 5, 10, 100]\n",
    "best_c = cross_validation_1(X_train, label_train, C_range, n=10)\n",
    "\n",
    "# 使用最优的参数C训练svm_linear模型\n",
    "# Train the svm_linear model using the optimal parameter C\n",
    "svm_linear = SVC(C=best_c, kernel='linear', random_state=0)\n",
    "svm_linear.fit(X_train, label_train)\n",
    "\n",
    "# 计算训练误差率\n",
    "# Calculate the training error rate\n",
    "svm_linear_hat1 = svm_linear.predict(X_train)\n",
    "svm_linear_ac1 = accuracy_score(svm_linear_hat1, label_train)\n",
    "svm_linear_er1 = 1 - svm_linear_ac1\n",
    "\n",
    "# 计算测试误差率\n",
    "# Calculate the test error rate\n",
    "svm_linear_hat2 = svm_linear.predict(X_test)\n",
    "svm_linear_ac2 = accuracy_score(svm_linear_hat2, label_test)\n",
    "svm_linear_er2 = 1 - svm_linear_ac2\n",
    "\n",
    "print('The error rate of the linear-kernel SVM on the training set is:', f'{svm_linear_er1:.4f}')\n",
    "print('The error rate of the linear-kernel SVM on the test set is:', f'{svm_linear_er2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "09ec9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_2(X, y, parameters_range, n=10):\n",
    "    \"\"\"\n",
    "    线性核SVM的交叉验证函数，默认10折，寻找最优的参数C和gamma(σ)\n",
    "    The cross-validation function for radial-kernel SVM, with the default of 10-fold, to find the optimal parameter C and gamma(σ)\n",
    "    因为大部分都和cross_validation_1函数一样，所以我就不写详细的注释了~\n",
    "    Since most of it is the same as the cross_validation_1 function, detailed comments won't be written.\n",
    "    \"\"\"\n",
    "    folds = kfold(X, y, n=n)\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    \n",
    "    for c in parameters_range['C']:\n",
    "        for gamma in parameters_range['gamma']:\n",
    "            scores = []\n",
    "            \n",
    "            for train_idx, val_idx in folds:\n",
    "                X_train_fold, y_train_fold = X[train_idx], y[train_idx]\n",
    "                X_val_fold, y_val_fold = X[val_idx], y[val_idx]\n",
    "\n",
    "                model = SVC(C=c, kernel='rbf', gamma=gamma, random_state=0)\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                \n",
    "                y_pred = model.predict(X_val_fold)\n",
    "                accuracy = np.mean(y_pred == y_val_fold)\n",
    "                scores.append(accuracy)\n",
    "            \n",
    "            mean_score = np.mean(scores)\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_params = {'C': c, 'gamma': gamma}\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "94bfcfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate of the radial-kernel SVM on the training set is: 0.1446\n",
      "The error rate of the radial-kernel SVM on the test set is: 0.4333\n"
     ]
    }
   ],
   "source": [
    "# (iii).SVM with radial kernel\n",
    "\n",
    "# 用字典存储参数C和gamma（有γ = 1/(2 * σ^2)）的设定范围，并使用10折交叉验证得到最优的c和gamma\n",
    "# Store the set ranges of parameters C and gamma (where γ = 1/(2 * σ²)) in a dictionary,and use 10-fold cross-validation to obtain the optimal c and gamma.\n",
    "parameters_range = {'C': [5, 10, 100], \n",
    "                  'gamma': [5, 10]}\n",
    "best_params = cross_validation_2(X_train, label_train, parameters_range, n=10)\n",
    "best_c = best_params['C']\n",
    "best_gamma = best_params['gamma']\n",
    "best_sigma = np.sqrt(1/(2*best_gamma)) if best_gamma > 0 else float('inf')\n",
    "\n",
    "svm_rbf = SVC(C=best_c, kernel='rbf', gamma=best_gamma, random_state=0)\n",
    "svm_rbf.fit(X_train, label_train)\n",
    "\n",
    "# 计算训练误差率\n",
    "# Calculate the training error rate\n",
    "svm_rbf_hat1 = svm_rbf.predict(X_train)\n",
    "svm_rbf_ac1 = accuracy_score(svm_rbf_hat1, label_train)\n",
    "svm_rbf_er1 = 1 - svm_rbf_ac1\n",
    "\n",
    "# 计算测试误差率\n",
    "# Calculate the test error rate\n",
    "svm_rbf_hat2 = svm_rbf.predict(X_test)\n",
    "svm_rbf_ac2 = accuracy_score(svm_rbf_hat2, label_test)\n",
    "svm_rbf_er2 = 1 - svm_rbf_ac2\n",
    "\n",
    "print('The error rate of the radial-kernel SVM on the training set is:', f'{svm_rbf_er1:.4f}')\n",
    "print('The error rate of the radial-kernel SVM on the test set is:', f'{svm_rbf_er2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "58d42a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t===== Comparison of Error Rates of Three Models =====\n",
      "Model\t\t\tTraining Set Error Rate\t\tTest Set Error Rate\n",
      "Logistic Regression\t0.4307\t\t\t\t0.4333\n",
      "Linear-kernel SVM\t0.4428\t\t\t\t0.5000\n",
      "Radial-kernel SVM\t0.1446\t\t\t\t0.4333\n"
     ]
    }
   ],
   "source": [
    "# 总结比较\n",
    "# Summary and comparison\n",
    "print('\\n\\t===== Comparison of Error Rates of Three Models =====')\n",
    "print('Model\\t\\t\\tTraining Set Error Rate\\t\\tTest Set Error Rate')\n",
    "print(f'Logistic Regression\\t{logistic_er1:.4f}\\t\\t\\t\\t{logistic_er2:.4f}')\n",
    "print(f'Linear-kernel SVM\\t{svm_linear_er1:.4f}\\t\\t\\t\\t{svm_linear_er2:.4f}')\n",
    "print(f'Radial-kernel SVM\\t{svm_rbf_er1:.4f}\\t\\t\\t\\t{svm_rbf_er2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b46682d",
   "metadata": {},
   "source": [
    "虽然目前看来训练的三个模型正确率都不十分高，不过我在给的所有数据上试验发现：当样本量变大后，三个模型都能显著优于随机分类，SVM分类的正确率更是可以超过0.6。说明应该还是有一定功能的。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
